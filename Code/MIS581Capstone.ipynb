{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **MIS581**\n",
    "Capstone Project\n",
    "BART\n",
    "Bay Area Rapid Transit Ridership Study"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.version\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "\n",
    "# standard set of includes for plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "import statistics\n",
    "import csv\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "import calendar\n",
    "import psycopg2\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics import tsaplots\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "print(\"Current Time =\", datetime.now())"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-f5cde92e357d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdatetime\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcalendar\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpsycopg2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mchi2_contingency\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def PGBart(query):\n",
    "    try:\n",
    "        query_results = []\n",
    "        conn = psycopg2.connect(host=\"10.0.0.206\", port=5432,\n",
    "                                database=\"bartridership\",\n",
    "                                user=\"postgres\",\n",
    "                                password=\"minden12k\")\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(query)\n",
    "        query_results = cur.fetchall()\n",
    "        # Close the cursor and connection to so the server can allocate\n",
    "        # bandwidth to other requests\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except (Exception, psycopg2.Error) as e:\n",
    "        print(\"Error in running the query: {}\".format(str(e)))\n",
    "    finally:\n",
    "        return query_results\n",
    "\n",
    "def PGBartLocal(query):\n",
    "    try:\n",
    "        query_results = []\n",
    "        conn = psycopg2.connect(host=\"localhost\", port=5432,\n",
    "                                database=\"bartridership\",\n",
    "                                user=\"postgres\",\n",
    "                                password=\"minden12k\")\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(query)\n",
    "        query_results = cur.fetchall()\n",
    "        # Close the cursor and connection to so the server can allocate\n",
    "        # bandwidth to other requests\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except (Exception, psycopg2.Error) as e:\n",
    "        print(\"Error in running the query: {}\".format(str(e)))\n",
    "    finally:\n",
    "        return query_results\n",
    "\n",
    "\n",
    "def GetAveragedWeekdayRidersToDest(dest, hour, years):\n",
    "    global smoothData, scal\n",
    "    query = \"\"\"\n",
    "                \n",
    "        select avg(cast(riders as double precision)), dest, \n",
    "            extract(DOW from depart_date) as dow,\n",
    "            extract(WEEK from depart_date) as week\n",
    "        from hourlystationqueue\n",
    "        where\n",
    "            extract(ISODOW from depart_date) in (1,2,3,4,5)\n",
    "        AND\n",
    "            dest = '{0}'\n",
    "        and\n",
    "            depart_hour = {1}\n",
    "        and \n",
    "            extract(MONTH from depart_date) in (1,2,3,4,5,6,7,8,9,10,11,12)\n",
    "        and\n",
    "            extract(YEAR from depart_date) in {2}\n",
    "        group by dest,  extract(WEEK from depart_date), extract(DOW from depart_date)\n",
    "                \n",
    "    \"\"\".format(dest, hour, years)\n",
    "    dat = PGBartLocal(query)\n",
    "    plotdata = list(map(lambda x: x[0], dat))\n",
    "    return plotdata\n",
    "\n",
    "\n",
    "def GetAverageDailyDestFrom(source, hour, year):\n",
    "    global smoothData, scal\n",
    "    query = \"\"\"\n",
    "                                \n",
    "        select AVG(riders) as riders, source, dest\n",
    "        from hourlystationqueue\n",
    "        where\n",
    "            extract(ISODOW from depart_date) in (1,2,3,4,5)\n",
    "        AND\n",
    "            source = '{0}'\n",
    "        AND \n",
    "            depart_hour = {1}\n",
    "        and \n",
    "            extract(YEAR from depart_date) = {2}\n",
    "        group by source, dest\n",
    "                \n",
    "    \"\"\".format(source, hour, year)\n",
    "\n",
    "    dat = PGBartLocal(query)\n",
    "    plotdata = list(map(lambda x: x, dat))\n",
    "    return plotdata"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def Decomposition(data, per):\n",
    "\n",
    "    decomposition = seasonal_decompose(data, model=\"additive\", period=per)\n",
    "    fig = decomposition.plot()\n",
    "    plt.show()\n",
    "\n",
    "def ACF(data, lags):\n",
    "    # Display the autocorrelation plot of your time series\n",
    "    fig = tsaplots.plot_acf(data, lags=lags)\n",
    "    plt.show()\n",
    "    # Display the partial autocorrelation plot of your time series\n",
    "    fig = tsaplots.plot_pacf(data, lags=lags)\n",
    "    plt.show()\n",
    "\n",
    "def SumSquares(ft):\n",
    "    try:\n",
    "        r =  np.sqrt(  np.square(ft.real) + np.square(ft.imag)  )\n",
    "    except(Exception) as e:\n",
    "        print(\"Exception: \", e)\n",
    "\n",
    "    return r\n",
    "\n",
    "def smoothTriangle(data, degree):\n",
    "    triangle=np.concatenate((np.arange(degree + 1), np.arange(degree)[::-1])) # up then down\n",
    "    smoothed=[]\n",
    "\n",
    "    for i in range(degree, len(data) - degree * 2):\n",
    "        point=data[i:i + len(triangle)] * triangle\n",
    "        smoothed.append(np.sum(point)/np.sum(triangle))\n",
    "    # Handle boundaries\n",
    "    smoothed=[smoothed[0]]*int(degree + degree/2) + smoothed\n",
    "    while len(smoothed) < len(data):\n",
    "        smoothed.append(smoothed[-1])\n",
    "    return smoothed\n",
    "\n",
    "def Smooth_1StandardDeviation(dataSet):\n",
    "    returnData = []\n",
    "    sdv = statistics.stdev(dataSet)\n",
    "    mn = statistics.mean(dataSet)\n",
    "    Maxthreshold = mn + (2.0 * sdv)\n",
    "    Minthreshold = mn - (2.0 * sdv)\n",
    "    for d in range(0, len(dataSet)):\n",
    "        if (dataSet[d] > Maxthreshold ):\n",
    "            print(d, ' : ' ,dataSet[d], mn+sdv)\n",
    "            returnData.append(mn + sdv)\n",
    "        elif (dataSet[d] < Minthreshold ):\n",
    "            print(d, ' : ' ,dataSet[d], mn-sdv)\n",
    "            returnData.append(mn - sdv)\n",
    "        else:\n",
    "            returnData.append(dataSet[d])\n",
    "    return returnData\n",
    "\n",
    "\n",
    "def CalcProp(dataArray):\n",
    "    tot: Decimal = 0.0\n",
    "    for d in dataArray:\n",
    "        tot = tot+float(d)\n",
    "    propList = list(map(lambda x: float( (float(x)/tot) )*100.0, dataArray))\n",
    "    return propList\n",
    "\n",
    "def ChiSqTest(d1,d2):\n",
    "    rejectHO = False\n",
    "    data = [d1, d2]\n",
    "    stat, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "    # interpret p-value\n",
    "    alpha = 0.05\n",
    "    if p <= alpha:\n",
    "        rejectHO = True\n",
    "    return rejectHO, p\n",
    "\n",
    "def ChiSqTestExp():\n",
    "    # defining the table\n",
    "    data = [[50000, 30000, 20000,40000,25000], [50000, 30000, 20000,38000,22000]]\n",
    "    data = [[10000, 900], [20000, 2100]]\n",
    "    stat, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "    d1 = list(map(lambda x: x/1000, data[0]))\n",
    "    d2 = list(map(lambda x: x/1000, data[1]))\n",
    "\n",
    "    data = [d1, d2]\n",
    "    stat, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "    d1 = CalcProp(data[0])\n",
    "    d2 = CalcProp(data[1])\n",
    "    data = [d1, d2]\n",
    "    stat, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "    # interpret p-value\n",
    "    alpha = 0.05\n",
    "    print(\"p value is \" + str(p))\n",
    "    if p <= alpha:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (H0 holds true)')\n",
    "    return p\n",
    "\n",
    "def RemoveSmallStationsPercent(per, l1, l2):\n",
    "    try:\n",
    "        propL1 = CalcProp(list(map(lambda x: x[0], l1)))\n",
    "        propL2 = CalcProp(list(map(lambda x: x[0], l2)))\n",
    "        l1p = []\n",
    "        l2p = []\n",
    "        for index, value in enumerate(propL1):\n",
    "            if propL1[index] > per and propL2[index] > per:\n",
    "                l1p.append(l1[index])\n",
    "                l2p.append(l2[index])\n",
    "\n",
    "    except(Exception) as e:\n",
    "        print(e)\n",
    "\n",
    "    return l1p, l2p\n",
    "\n",
    "def RemoveSmallStations(per, l1, l2):\n",
    "    try:\n",
    "        dataL1 = (list(map(lambda x: x[0], l1)))\n",
    "        dataL2 = (list(map(lambda x: x[0], l2)))\n",
    "        l1p = []\n",
    "        l2p = []\n",
    "        for index, value in enumerate(dataL1):\n",
    "            if dataL1[index] > per and dataL2[index] > per:\n",
    "                l1p.append(l1[index])\n",
    "                l2p.append(l2[index])\n",
    "\n",
    "    except(Exception) as e:\n",
    "        print(e)\n",
    "\n",
    "    return l1p, l2p"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def RunBARTTimeSeries():\n",
    "    plotdata = GetAveragedWeekdayRidersToDest('EMBR', 7, '(2013,2014,2015,2016,2017,2018,2019)')\n",
    "\n",
    "    PlotTimeSeriesWithLimitBars(plotdata)\n",
    "\n",
    "    smoothData = BartLibs.Smooth_1StandardDeviation(plotdata)\n",
    "    PlotTimeSeriesWithLimitBars(smoothData)\n",
    "\n",
    "    PlotTimeSeriesFFT(smoothData)\n",
    "\n",
    "    BartLibs.Decomposition(smoothData, 5)\n",
    "    BartLibs.ACF(smoothData, 10)\n",
    "\n",
    "\n",
    "def PlotTimeSeriesFFT(smoothData):\n",
    "    smoothMean = statistics.mean(smoothData)\n",
    "    smoothDataZeroed = list(map(lambda x: x - smoothMean, smoothData))\n",
    "    ft = np.fft.fft(smoothDataZeroed)\n",
    "    realAmplitudes = list(map(lambda x: BartLibs.SumSquares(x), ft))\n",
    "    realAmpsLen = len(realAmplitudes)\n",
    "    fftScale = 2.0 / (realAmpsLen)\n",
    "    realAmplitudesScaled = list(map(lambda x: fftScale * x, realAmplitudes))\n",
    "    plt.plot(realAmplitudesScaled[:int(realAmpsLen / 3.0)])\n",
    "    plt.suptitle(\"Fourrier Transform Rider Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def PlotTimeSeriesWithLimitBars(plotdata):\n",
    "    rawLen = len(plotdata)\n",
    "    x = list(range(rawLen))\n",
    "    plt.plot(x, plotdata,\n",
    "             color='blue',\n",
    "             linewidth=1\n",
    "             )\n",
    "    sdv = statistics.stdev(plotdata)\n",
    "    mn = statistics.mean(plotdata)\n",
    "    Maxthreshold = mn + (2.0 * sdv)\n",
    "    Minthreshold = mn - (2.0 * sdv)\n",
    "    plt.hlines(Maxthreshold, 0, rawLen, colors=\"red\")\n",
    "    plt.hlines(Minthreshold, 0, rawLen, colors=\"red\")\n",
    "    plt.suptitle(\"BART Daily Rider EMBR 7:00AM\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def CosFFT():\n",
    "    N = 512\n",
    "    T = 1/N\n",
    "    F = int(20)\n",
    "    P = int(np.round(N/F))\n",
    "    print(\"Frequency: \", F)\n",
    "    print(\"Period: \",P)\n",
    "    x = np.linspace(0.0, N, N, endpoint=False)\n",
    "    y = 10*np.sin(F * 2.0*np.pi*(x/N)) #+ 5*np.sin(10 * 2.0*np.pi*x)\n",
    "    y = list(map(lambda x: x - statistics.mean(y), y))\n",
    "    plt.plot(x, y,\n",
    "             color='blue',\n",
    "             linewidth=1\n",
    "             )\n",
    "    plt.show()\n",
    "\n",
    "    ft = np.fft.fft(y)\n",
    "    rt = []\n",
    "    rt = list(map(lambda x: BartLibs.SumSquares(x), ft))\n",
    "    le = len(rt)\n",
    "    scal = 2 / le\n",
    "    rt = list(map(lambda x: scal * x, rt))\n",
    "    plt.plot(rt[:int(N/2)])\n",
    "    plt.show()\n",
    "\n",
    "    BartLibs.Decomposition(y, P)\n",
    "    BartLibs.ACF(y, P*2 )\n",
    "\n",
    "def GetPITTDistroCompare():\n",
    "\n",
    "    plotData14 = GetAverageDailyDestFrom('PITT', 7, 2018)\n",
    "    plotData15 = GetAverageDailyDestFrom('PITT', 7, 2019)\n",
    "\n",
    "    plotData14S, plotData15S = BartLibs.RemoveSmallStations(5, plotData14, plotData15)\n",
    "\n",
    "    pData14 = list(map(lambda x: x[0], plotData14S))\n",
    "    pData15 = list(map(lambda x: x[0], plotData15S))\n",
    "\n",
    "    rejectHO, pVal = BartLibs.ChiSqTest(pData14, pData15)\n",
    "    print(\"Reject HO: \", rejectHO, \" p-value :\", pVal)\n",
    "\n",
    "    cat_names = list(map(lambda x: x[2], plotData14S))\n",
    "    #add data to bar chart\n",
    "    le = len(pData14)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    ax1.bar(cat_names, pData14)\n",
    "    ax2.bar(cat_names, pData15)\n",
    "\n",
    "    ax1.set_title(\"2014\")\n",
    "    ax2.set_title(\"2015\")\n",
    "\n",
    "    hypTest = \"Rider Proportion\\nAlpha = '{0:.9f}'\\nReject H0:'{1}' \".format(pVal,rejectHO)\n",
    "    plt.suptitle(hypTest)\n",
    "\n",
    "    ax1.tick_params(labelrotation=45)\n",
    "    ax2.tick_params(labelrotation=45)\n",
    "\n",
    "    myLocator = mticker.MultipleLocator(4)\n",
    "    ax1.xaxis.set_major_locator(myLocator)\n",
    "    ax2.xaxis.set_major_locator(myLocator)\n",
    "\n",
    "    # set the spacing between subplots\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=.7,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "def ShowAverageDailyDestFrom():\n",
    "    plotData = GetAverageDailyDestFrom('PITT', 7, 2018)\n",
    "    cat_names = list(map(lambda x: x[2], plotData))\n",
    "    barValues = list(map(lambda x: x[0], plotData))\n",
    "    plt.bar(cat_names, barValues)\n",
    "    plt.suptitle('Riders Pittsburgh Station 2018')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Riders')\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    RunBARTTimeSeries()\n",
    "\n",
    "    ShowAverageDailyDestFrom()\n",
    "\n",
    "    GetPITTDistroCompare()\n",
    "\n",
    "except(Exception) as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    print(\"Completed\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}